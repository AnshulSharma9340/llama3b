# Project Settings
project_name: "Medical-Llama-3B-Nano"
output_dir: "./outputs"

# Model Settings
model_name: "meta-llama/Llama-3.2-3B-Instruct"
use_4bit: true        
max_seq_length: 2048  


batch_size: 16        
grad_accumulation: 2  
learning_rate: 2.0e-4
epochs: 3           
optim: "paged_adamw_32bit"

# LoRA Params
lora_r: 32           
lora_alpha: 64
lora_dropout: 0.05

# Data Paths (Ensure these folders exist on VM)
raw_data_dir: "./sampled_data"
processed_data_dir: "./data/ready"
